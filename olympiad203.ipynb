{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"## data wrangling tools\nimport pandas as pd\npd.options.mode.chained_assignment = None \nimport numpy as np\nimport os\n\n#stats for ensembling\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\n#Preprocessing\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn import preprocessing\n\n#Ensembling\nfrom scipy import stats as st","metadata":{"execution":{"iopub.status.busy":"2023-09-18T15:26:20.368201Z","iopub.execute_input":"2023-09-18T15:26:20.369785Z","iopub.status.idle":"2023-09-18T15:26:20.376703Z","shell.execute_reply.started":"2023-09-18T15:26:20.369731Z","shell.execute_reply":"2023-09-18T15:26:20.375538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Category encoder\ndef cat_encoder(X_train, X_test, cat_cols):\n    encoder = OrdinalEncoder()\n    train_encoder = encoder.fit_transform(X_train[cat_cols]).astype(int)\n    test_encoder = encoder.transform(X_test[cat_cols]).astype(int)\n    for col in cat_cols:\n        X_train[col] = train_encoder[:, cat_cols.index(col)]\n        X_test[col] = test_encoder[:, cat_cols.index(col)]\n    encoder_cols = cat_cols\n    return X_train, X_test, encoder_cols","metadata":{"execution":{"iopub.status.busy":"2023-09-18T15:26:20.489061Z","iopub.execute_input":"2023-09-18T15:26:20.490330Z","iopub.status.idle":"2023-09-18T15:26:20.496931Z","shell.execute_reply.started":"2023-09-18T15:26:20.490280Z","shell.execute_reply":"2023-09-18T15:26:20.496065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.base import TransformerMixin,BaseEstimator\nfrom sklearn.feature_selection import VarianceThreshold\n\n#Implementingthe Transformer class\nclass low_var(TransformerMixin):\n    def __init__(self,threshold=0.3):\n        self.threshold=threshold\n    def fit(self,X,y=None):\n        col_vars=X.var()\n        self.col_to_drop=col_vars[col_vars<self.threshold].index\n        return self\n    def transform(self,X):\n        assert self.col_to_drop is not None, 'Drop_col error, must be fitted before predict'\n        X.drop(self.col_to_drop, axis=1, inplace=True)\n        return X","metadata":{"execution":{"iopub.status.busy":"2023-09-18T15:26:20.561677Z","iopub.execute_input":"2023-09-18T15:26:20.562312Z","iopub.status.idle":"2023-09-18T15:26:20.569683Z","shell.execute_reply.started":"2023-09-18T15:26:20.562280Z","shell.execute_reply":"2023-09-18T15:26:20.568394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Reading the dataset\nFILEPATH=\"/kaggle/input/analytic-olympiad\"\ndf_train=pd.read_csv(os.path.join(FILEPATH,'train.csv'))\ndf_test=pd.read_csv(os.path.join(FILEPATH,'test.csv'))\ndf_train=df_train.fillna(0)\ndf_test=df_test.fillna(0)\n\n\n#Defining the features\ntarget_col01='primary_close_flag'\ntarget_col02='final_close_flag'\ncat_cols=df_train.select_dtypes(include=\"object\").columns.to_list()\nnum_cols=df_train.select_dtypes(include=[\"int64\",\"float64\"]).columns.to_list()[:-2]\n\n#Definging the training and testing dataset\nX = df_train.drop([f'{target_col01}',f'{target_col02}'],axis=1).reset_index(drop=True)\ny = df_train[f'{target_col01}'].reset_index(drop=True)\nX_=df_test.copy()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T15:26:20.584752Z","iopub.execute_input":"2023-09-18T15:26:20.585558Z","iopub.status.idle":"2023-09-18T15:26:39.636101Z","shell.execute_reply.started":"2023-09-18T15:26:20.585526Z","shell.execute_reply":"2023-09-18T15:26:39.634722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop_col\nencoded_features = ['encoded_payment_' + str(i) for i in range(25)]\ndrop_cols = ['customer_id', 'firstname', 'lastname']\nX.drop(drop_cols, axis=1, inplace=True)\nX_.drop(drop_cols, axis=1, inplace=True)\n\n#Reassigning cat_cols\ncat_cols=X.select_dtypes(include=\"object\").columns.to_list()\nnum_cols=X.select_dtypes(include=[\"int64\",\"float64\"]).columns.to_list()[:-2]\n\n#Adding more column\nX['Due_']=X['final_term']-X['primary_term']\nX['Delay_']=X['days_till_final_close']-X['days_till_primary_close']\nX['Verifications_delay']=X['days_till_final_close']-X['final_term']\nX['Verifications_time']=X['days_till_primary_close']-X['primary_term']\nX['Verifications_'] = X['days_till_primary_close'] * X['primary_term']\nX['days_up']=X['primary_term']-X['days_till_primary_close']\n\n\nX_['Due_']=X_['final_term']-X_['primary_term']\nX_['Delay_']=X_['days_till_final_close']-X_['days_till_primary_close']\nX_['Verifications_delay']=X_['days_till_final_close']-X_['final_term']\nX_['Verifications_time']=X_['days_till_primary_close']-X_['primary_term']\nX_['Verifications_']=X_['days_till_primary_close']*X_['primary_term']\nX_['days_up']=X_['primary_term']-X_['days_till_primary_close']\n\n# for df in [X,X_]:\n#     try:\n#         df['Verifications_ratio'] = df['days_till_primary_close'] // df['primary_term']\n#     except ZeroDivisionError:\n#         df['Verifications_ratio'] = 0\n    \n#Removing columns with low variance\n# category_encoders\nX, X_, cat_cols = cat_encoder(X, X_, cat_cols)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T15:26:39.638400Z","iopub.execute_input":"2023-09-18T15:26:39.639056Z","iopub.status.idle":"2023-09-18T15:26:45.706266Z","shell.execute_reply.started":"2023-09-18T15:26:39.639019Z","shell.execute_reply":"2023-09-18T15:26:45.704735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Normalization of data.\nscale=preprocessing.StandardScaler()\nX=pd.DataFrame(scale.fit_transform(X),index=X.index,columns=X.columns)\nX_=pd.DataFrame(scale.transform(X_),index=X_.index,columns=X_.columns)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T15:26:45.707990Z","iopub.execute_input":"2023-09-18T15:26:45.708371Z","iopub.status.idle":"2023-09-18T15:26:47.375305Z","shell.execute_reply.started":"2023-09-18T15:26:45.708342Z","shell.execute_reply":"2023-09-18T15:26:47.373868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"####################### XGB CLASSSIFIER #######################\nfrom xgboost import XGBClassifier\ndef xgb_model():\n    xgb_01={\n         'n_estimators': 120,\n         'learning_rate': 0.5619556985982561,\n         'max_depth': 136,\n         'min_child_weight': 10,\n         'reg_alpha': 0.4632934146772244,\n         'reg_lambda': 13,\n         'gamma': 0.7471461478419492,\n         'colsample_bytree': 0.8939543526804394,\n         'colsample_bylevel': 0.33219308427147426 \n    }\n    xgb_02={\n         'n_estimators': 320,\n         'learning_rate': 0.6771864073202802,\n         'max_depth': 179,\n         'min_child_weight': 14,\n         'reg_alpha': 0.6456816599087696,\n         'reg_lambda': 10,\n         'gamma': 1.264355703745565,\n         'colsample_bytree': 0.6432920257822892,\n         'colsample_bylevel': 0.4547371625752076\n    }\n    \n   # return XGBClassifier(**xgb_01)\n    return XGBClassifier(**xgb_01)\n################## LGBM CLASSIFIER ############################\nfrom lightgbm import LGBMClassifier\ndef lgbm_model():\n    lgbm_01={\n         'n_estimators': 229,\n         'learning_rate': 0.5185147161031304,\n         'max_depth': 70,\n         'min_child_weight': 10,\n         'reg_alpha': 0.699472780990506,\n         'reg_lambda': 7,\n         'colsample_bytree': 0.3072359964466818\n    }\n    lgbm_02={\n         'n_estimators': 327,\n         'learning_rate': 0.7862270379341548,\n         'max_depth': 199,\n         'min_child_weight': 13,\n         'reg_alpha': 0.8800992852019061,\n         'reg_lambda': 6,\n         'colsample_bytree': 0.8218273150299635\n    }\n    return LGBMClassifier(**lgbm_01)\n#     return LGBMClassifier(**lgbm_01)\n    \n####################### CATBOOST CLASSIFIER ###############\nfrom catboost import CatBoostClassifier \ndef cat_model():\n    cat_01={}\n    #return CatBoostClassifier(**cat_01)\n    return CatBoostClassifier(**cat_01)\n\n############## TPOT Classifier ###############\nfrom tpot import TPOTClassifier\ndef tpot_model():\n    tpot_01={\n        'generations':2, \n        'population_size':15,\n        'scoring':'accuracy'\n    }\n    return TPOTClassifier(**tpot_01)\n\n############## RANDOM FOREST ########\nfrom sklearn.ensemble import RandomForestClassifier\ndef forest_model():\n    return RandomForestClassifier()\n\n############## HIST CLASSIFIER\nfrom sklearn.ensemble import HistGradientBoostingClassifier\ndef hist_model():\n    return HistGradientBoostingClassifier()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T15:26:47.378647Z","iopub.execute_input":"2023-09-18T15:26:47.379038Z","iopub.status.idle":"2023-09-18T15:26:47.394557Z","shell.execute_reply.started":"2023-09-18T15:26:47.379007Z","shell.execute_reply":"2023-09-18T15:26:47.392726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import regularizers\nimport tensorflow as tf\n\nfrom tensorflow import keras\nearly_stopping = keras.callbacks.EarlyStopping(\n    patience=15,\n    monitor='val_binary_crossentropy',\n    min_delta=0.001,\n    restore_best_weights=True,\n)\n\n#It is better to reduce the learning rate as we do training.\nlr_schedule = keras.optimizers.schedules.InverseTimeDecay(\n  0.001,\n  decay_steps=X.shape[0]*1,\n  decay_rate=1,\n  staircase=False)\n\ndef tf_model():\n    model_tf=tf.keras.Sequential([\n        keras.layers.Input(shape=[57,]),\n        keras.layers.Dense(256, activation='relu',kernel_regularizer=regularizers.l2(0.003)),\n        keras.layers.Dropout(0.2),\n        keras.layers.Dense(128, activation='relu',kernel_regularizer=regularizers.l2(0.003),),\n        keras.layers.Dropout(0.2),\n        keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001),),\n        keras.layers.Dense(8, activation='relu'),\n        keras.layers.Dropout(0.2),\n        keras.layers.Dense(2, activation='sigmoid')])\n        \n    model_tf.compile(optimizer= keras.optimizers.Adam(lr_schedule),\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n    return model_tf","metadata":{"execution":{"iopub.status.busy":"2023-09-18T15:26:47.397165Z","iopub.execute_input":"2023-09-18T15:26:47.397944Z","iopub.status.idle":"2023-09-18T15:26:47.415919Z","shell.execute_reply.started":"2023-09-18T15:26:47.397817Z","shell.execute_reply":"2023-09-18T15:26:47.413816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import eli5\nfrom eli5.sklearn import PermutationImportance\nmodel = lgbm_model()\nmodel.fit(X, y)\nperm = PermutationImportance(model, random_state=1).fit(X.head(1500), y.head(1500))\neli5.show_weights(perm, feature_names = X.columns.tolist())\n#primary_term,days_till_primary_close ","metadata":{"execution":{"iopub.status.busy":"2023-09-18T16:11:07.514970Z","iopub.execute_input":"2023-09-18T16:11:07.515436Z","iopub.status.idle":"2023-09-18T16:11:17.540315Z","shell.execute_reply.started":"2023-09-18T16:11:07.515401Z","shell.execute_reply":"2023-09-18T16:11:17.539032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_importance=eli5.explain_weights_df(perm, feature_names=X.columns.tolist())\ndrop_col = feature_importance[feature_importance['weight'] == 0]\ndrop_col = drop_col['feature'].tolist()\n# for col in drop_col:\n#     X.drop([col], axis=1, inplace=True)\n#     X_.drop([col],axis =1, inplace =True)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T16:11:17.542026Z","iopub.execute_input":"2023-09-18T16:11:17.542390Z","iopub.status.idle":"2023-09-18T16:11:17.586752Z","shell.execute_reply.started":"2023-09-18T16:11:17.542359Z","shell.execute_reply":"2023-09-18T16:11:17.585767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# eval_set=[(X_val, y_val)]\nn_split=5\nrandom_state=42\npreds=pd.DataFrame()\nkf = StratifiedKFold(n_splits=n_split, random_state=random_state, shuffle=True)\nfor i,(train_index, val_index) in enumerate(kf.split(X,y)):\n    models={}\n    class_probs={}\n    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n    \n    ###########Deep Neural_MODEL###################\n    y_train, y_val = [tf.keras.utils.to_categorical(y.iloc[index]) for index in [train_index, val_index]]\n    model=tf_model()\n   # model.fit(X_train,y_train,validation_data=[X_val,y_val],epochs=1,\n                    # callbacks=[early_stopping],batch_size=200)\n   # models['tf_model']=model\n    \n    ######Non Neural Neural Networks#######################\n    y_train, y_val = y.iloc[train_index],y.iloc[val_index]\n    ###XGB classifier ########\n    model=xgb_model()\n    model.fit(X_train, y_train)\n    models['xgb_model']=model\n    ####LGBM classifier########\n    model=lgbm_model()\n    model.fit(X_train, y_train)\n    models['lgbm_model']=model\n    ####CAT classifier########\n    model=cat_model()\n    model.fit(X_train, y_train)\n    models['cat_model']=model\n    ####### RANDOM FOREST ####\n    model=forest_model()\n    model.fit(X_train,y_train)\n    models['forest_model']=model\n    ######### HIST GRAD#######\n    model=hist_model()\n    model.fit(X_train,y_train)\n    models['hist_model']=model\n    \n    \n    \n    #####Ensemble Models#######################\n    for model_name, model in models.items():\n        if model_name =='tf_model':\n             probs = model.predict(X_)\n        else :\n            probs=model.predict_proba(X_)\n        class_probs[model_name] = probs\n    ensemble_probs = np.mean(list(class_probs.values()), axis=0)\n    probs= np.argmax(ensemble_probs, axis=1)\n    preds.insert(loc=0, column=f'fold_{i+1}', value=probs)\n    \n    print(f'############## FOLD{i+1}########################')","metadata":{"execution":{"iopub.status.busy":"2023-09-18T15:28:45.783487Z","iopub.execute_input":"2023-09-18T15:28:45.783819Z","iopub.status.idle":"2023-09-18T15:50:29.463719Z","shell.execute_reply.started":"2023-09-18T15:28:45.783791Z","shell.execute_reply":"2023-09-18T15:50:29.462291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy import stats as st\npreds['mode']=preds.apply(lambda x:st.mode(x)[0],axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T15:50:29.465475Z","iopub.execute_input":"2023-09-18T15:50:29.465848Z","iopub.status.idle":"2023-09-18T15:54:04.792154Z","shell.execute_reply.started":"2023-09-18T15:50:29.465819Z","shell.execute_reply":"2023-09-18T15:54:04.791023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfig, axs=plt.subplots(2,2,figsize=(12, 5*2))\nax=axs.flatten()\nfor i,model in enumerate(['xgb_model','lgbm_model','cat_model','forest_model']):\n    feat_imp = pd.Series(models[model].feature_importances_, index=X.columns)\n    feat_imp.nlargest(10).plot(kind='barh',ax=ax[i])\n    plt.xticks(rotation=45)\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2023-09-18T16:09:27.468587Z","iopub.execute_input":"2023-09-18T16:09:27.469045Z","iopub.status.idle":"2023-09-18T16:09:28.570605Z","shell.execute_reply.started":"2023-09-18T16:09:27.469012Z","shell.execute_reply":"2023-09-18T16:09:28.569488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result=pd.read_csv('/kaggle/input/trivial-base/submission_trivial_base.csv')\nresult[f'{target_col01}']=preds['mode']\nresult.to_csv('big_milf.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-18T15:54:04.795460Z","iopub.execute_input":"2023-09-18T15:54:04.795781Z","iopub.status.idle":"2023-09-18T15:54:05.860550Z","shell.execute_reply.started":"2023-09-18T15:54:04.795754Z","shell.execute_reply":"2023-09-18T15:54:05.859446Z"},"trusted":true},"execution_count":null,"outputs":[]}]}